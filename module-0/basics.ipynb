{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72036cc-42d2-477f-bad5-506a6a237bf6",
   "metadata": {},
   "source": [
    "# in terminal / cli\n",
    "\n",
    "#!pip install langchain-anthropic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# Basic Setup\n",
    "\n",
    "Here, we will test whether calling your API Models is working. \n",
    "With LangChain, one can build LLM applications. One type of LLM application you can build is an agent.  \n",
    "\n",
    "In practice, it can be difficult to build systems that reliably execute on these tasks. As LangChain worked with their users to put agents into production, they have learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, LangChain built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## LangGraph Studio\n",
    "\n",
    "[LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), is an IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this workshop, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host Chat Models, they rely on third party integration. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain. By default, we will use [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) because it is popular and performant. please ensure that you have an `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a how-do for all the things that you can do with chat models, but we'll show a few highlights. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-openai` package. With this, we can instantiate our `ChatOpenAI` model object. If you are signing up for the API for the first time, you should receive [free credits](https://community.openai.com/t/understanding-api-limits-and-free-tier/498517) that can be applied to any of the models. You can see pricing for various models [here](https://openai.com/api/pricing/). The notebooks will default to `gpt-4o` because it's a good balance of quality, price, and speed [see more here](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini), but you can also opt for the lower priced `gpt-3.5` series models. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "Chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_703d4ff298', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cd9925b-e4b0-4877-a4b7-673aba63c3d2-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Ryan\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-98cbc139-9eed-4806-9400-2d57e555a1c4-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809fe0f-8ff8-4dbb-a87e-0bac0cdcdcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Import Other Chat Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3b3fac9-9418-41b1-974c-871c0f2740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70236409-2b54-429a-be4f-a260134e3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "#from langchain_core.messages import AIMessage, HumanMessage #already imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cc2db5f-2329-453b-8f7d-c7ca92ac40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_chat = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b58b328-6a21-453a-956d-09ed7c24aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26d592e1-d8f4-4fb2-87dc-7e209d27dcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Taiwan is Taipei. It is located in the northern part of the island and is the political, economic, and cultural center of Taiwan. Taipei is also the most populous city in Taiwan, with a population of approximately 2.6 million people in the city proper and over 7 million in the metropolitan area.\\n\\nTaipei is home to many important government institutions, including the Office of the President, the Executive Yuan, and the Legislative Yuan. The city is also known for its modern infrastructure, vibrant nightlife, and diverse cuisine. Some famous landmarks in Taipei include Taipei 101 (a skyscraper that was once the tallest building in the world), the National Palace Museum, and the Chiang Kai-shek Memorial Hall.', additional_kwargs={}, response_metadata={'id': 'msg_01AEHy1vRLWUfcuGg9iPfu3o', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 14, 'output_tokens': 165}}, id='run-a89cc5df-b9bb-432e-a38f-ab2472d0c112-0', usage_metadata={'input_tokens': 14, 'output_tokens': 165, 'total_tokens': 179, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a message\n",
    "msg = HumanMessage(content=\"What is the capital of Taiwan?\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "anthropic_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "[Tavily](https://tavily.com/) is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. it's easy to sign up and offers a free tier. We will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091dff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is Interaction Design?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.geeksforgeeks.org/whai-is-interaction-design/',\n",
       "  'content': 'Interaction design is the process of creating digital products, such as websites and apps, that are easy and enjoyable to use. It focuses on how users interact with these products, ensuring that every click, swipe, and action feels natural and intuitive. This involves designing buttons, menus, and other interactive elements to make sure they'},\n",
       " {'url': 'https://www.interaction-design.org/literature/topics/interaction-design',\n",
       "  'content': \"Interaction Design (IxD) is the design of interactive products and services in which a designer's focus goes beyond the item in development to include the way users will interact with it. Thus, close scrutiny of users' needs, limitations and contexts, etc. empowers designers to customize output to suit precise demands.\"},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Interaction_design',\n",
       "  'content': 'Interaction design, often abbreviated as IxD, is \"the practice of designing interactive digital products, environments, systems, and services.\" [1]: xxvii, 30 While interaction design has an interest in form (similar to other design fields), its main area of focus rests on behavior.[1]: xxvii, 30 Rather than analyzing how things are, interaction design synthesizes and imagines things as they'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae94054-fb96-48e1-bd99-b7b95ef4a11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991bd2d-691b-46a2-b67c-2175852f2faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b68b54-28f8-4bcd-a06a-eaf79f713743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
